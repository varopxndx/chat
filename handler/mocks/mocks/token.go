// Code generated by mockery v2.14.0. DO NOT EDIT.

package mocks

import (
	model "github.com/varopxndx/chat/model"

	mock "github.com/stretchr/testify/mock"
)

// Tokenizer is an autogenerated mock type for the Tokenizer type
type Tokenizer struct {
	mock.Mock
}

// GenerateToken provides a mock function with given fields: user
func (_m *Tokenizer) GenerateToken(user model.User) (string, error) {
	ret := _m.Called(user)

	var r0 string
	if rf, ok := ret.Get(0).(func(model.User) string); ok {
		r0 = rf(user)
	} else {
		r0 = ret.Get(0).(string)
	}

	var r1 error
	if rf, ok := ret.Get(1).(func(model.User) error); ok {
		r1 = rf(user)
	} else {
		r1 = ret.Error(1)
	}

	return r0, r1
}

type mockConstructorTestingTNewTokenizer interface {
	mock.TestingT
	Cleanup(func())
}

// NewTokenizer creates a new instance of Tokenizer. It also registers a testing interface on the mock and a cleanup function to assert the mocks expectations.
func NewTokenizer(t mockConstructorTestingTNewTokenizer) *Tokenizer {
	mock := &Tokenizer{}
	mock.Mock.Test(t)

	t.Cleanup(func() { mock.AssertExpectations(t) })

	return mock
}
